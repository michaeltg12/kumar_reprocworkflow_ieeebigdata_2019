\section{Introduction}
Rapid growth in observational technologies, data management, and
sharing infrastructure has enabled a new era of big data enabled
scientific
discovery in a wide range of disciplines. However, ensuring the high
quality of the data is crucial for accurate and reliable scientific
research and decision making. Management of data quality
presents specific challenges for environmental monitoring networks that
operate in
large numbers of distributed facilities in remote regions of the world,
like the U.S. Department of Energy's Atmospheric Radiation Measurement (ARM)
program (\url{https://arm.gov}). Ensuring high quality of data to
scientific community requires not only  the assessment and
documentation of data quality issues but also appropriate data reprocessing to
address and improve the data quality.
It is equally important is to capture the provenance of data at every step of
its life cycle that are comprehensive, timely, and transparently
communicated to the data users.
Performing data processing at the scale of a scientific data center
like ARM poses a big data challenge. Diversity of sensors and instruments
also call for an comprehensive metadata and data processing automation.
The sheer volume of the data necessitates state-of-the-art parallel processing,
efficient data movement, I/O, and provenance tracking and management.
In this paper we describe a provenance-aware workflow for
data quality improvement of continuously growing
atmospheric science data streams within ARM's Petabyte scale archive.


